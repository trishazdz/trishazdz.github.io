<!DOCTYPE html>
<html>
<head>
	<title>Elisa Kim Fromboluti | Art Prize 2015</title>

	<meta charset="UTF-8" />
	<meta name="description" content="Ellie Kim Fromboluti's Artprize entry" />

	<meta name="viewport" content="width=device-width, initial-scale=1.0" />

	<link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700|PT+Sans:400,700|PT+Sans+Narrow|PT+Sans+Caption' rel='stylesheet' type='text/css'>

	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
	<link rel="stylesheet" href="style.css">

</head>

<body>

<div class="container">
	<header>
		<embed src="images/top.svg" type="image/svg+xml" id="top-svg" />

		<div class="col-sm-8">
				<h1 id="project-title">Rhythm in the Brain</h1>
				<h2 id="project-description">a portable science experiment</h2>
				<p class="col-md-10" id="project-description-more">
					This <a href="http://www.artprize.org/elisa-kim-fromboluti/2015/tempo-in-the-brain-a-science-experience">ArtPrize entry</a> is an experiment investigating how perceptual biases 
					influence how we experience rhythmic sequences, such as those found in music.
				</p>

				<div id="data-links" class="hidden-xs">
					<div class="col-sm-7"> 
						<a href="#data">look at the data</a>
					</div>
					<div class="col-sm-5">
						<a href="#info">learn more</a>
					</div>
				</div>
		</div>

		<div class="col-sm-4 logistics">
			<h1 class="">Elisa Kim <br>Fromboluti</h1>
			<h2 class="">61025</h2>
			<p>9/23 &mdash; 10/11, 2015</p>
			<span>
				Entry showing at <br>
				Fat Johnny's <br>
				95 Monroe Center <br>
				Grand Rapids, MI 49503
			</span>
			
		</div>

		<div id="data-links-mobile" class="visible-xs">
			<div class="col-sm-7"> 
				<a href="#data">look at the data</a>
			</div>
			<div class="col-sm-5">
				<a href="#info">learn more</a>
			</div>
		</div>
	</header>

	<div class="content">
			<section class="row" id="data-visualization">
				<div class="col-sm-12">
					<h2 id="data">experiment data</h2>
				</div>

				<div class="col-sm-4">
						<p>
							Input your Participant ID to find your data.
							If you can't remember it or didn't participate, use 
							the data loaded currently in the visualization.
						</p>

						<p>
							Play the entire chain to watch 
							changes across generations, or slide the bar to view one
							generation at a time.
						</p>

						<p>
							When exploring chains look for decreasing variation in 
							tempo or rhythmic pattern, which suggests that 
							the rhythm has approached whatever bias most people 
							hold for tempo/rhythm. A lack of convergence suggests
							differences amongst the participants, and no 
							shared preference for a certain tempo or rhythmic pattern.
						</p>

						<p>
							Chains might converge then diverge when an individual who's 
							biases differ from an otherwise homogeneous group contributes. 
							That might happen if, for instance, a child (&lt;10 y.o.)  contributes 
							to a chain consisting of mostly adults (18 to 60 years old). 
							That child will have a different tempo bias, 
							and their reproductions will likely be both faster and more 
							variable than the average adult. This will de-stabalize the 
							chain &mdash; nudge it towards a faster tempo, and possibly  
							a non-isochronous pattern.
						</p>
				</div>

					<div class="col-sm-8" id="dv-container">
						<form id="sessionFetchForm" data-bind="submit: fetchSession">
							<input id="sessionIdInput" type="number" data-bind="textInput: sessionId" placeholder=" Participant ID" />
							<button class="btn btn-default" data-bind="css: {disabled: !sessionId()}" type="submit">Find Data</button>
						</form>

						<p class="warning">
							<span data-bind="text: errorId"></span><span data-bind="text: error"></span>
						</p>

						<div data-bind="if: session">
							<p id="activeSession">Showing Participant ID: <span data-bind="text: activeSessionId"></span></p>
						</div>

						<div id="canvas-container"></div>

						<div class="row">
							<div id="slider" data-bind="if: chain">
								<div class="col-sm-2">
									<button id="chain-play" class="btn btn-default" data-bind="click: chainToggle">
										<span data-bind="if: !chainPlaying()">Play Chain</span>
										<span data-bind="if: chainPlaying()">Stop</span>
									</button>
								</div>


								<div class="col-sm-9" id="slide">
									<div>
										<input type="range" step="1"
											data-bind="value: slideInput, valueUpdate: 'input', attr: {min: 1, max: chain().sessions.length}"
											/>
									</div>
								</div>

							</div>
						</div>
					</div>
			</section>

			<section class="row">
				<h2 id="info" class="col-sm-12">about this experiment</h2>

				<div class="col-sm-8">
					<iframe class="hidden-xs" width="100%" height="315" src="https://www.youtube.com/embed/cbKG6igEwvU" frameborder="0" style="margin-bottom: 25px" allowfullscreen></iframe>

					<iframe class="visible-xs" width="100%" height="240`" src="https://www.youtube.com/embed/cbKG6igEwvU" frameborder="0" style="margin-bottom: 25px" allowfullscreen></iframe>
				</div>

				<div class="col-sm-4">
				</div>

				<div class="col-sm-8">
					
					<p class="">
						Have you ever wondered why music makes you want to move? It’s because nearly everyone is sensitive to the differences in the pace or structure of music. Even infants can detect differences in rhythmic patterns!
					</p>
					<p class="">
						How? Researchers are not completely sure, but they have found evidence of a network of brain regions that processes beats, and therefore helps us perceive rhythm. For example, two brain regions commonly associated with movement, the <a href="https://en.wikipedia.org/wiki/Supplementary_motor_area">supplementary motor area</a> (SMA) and the <a href="https://en.wikipedia.org/wiki/Basal_ganglia">basal ganglia</a>, are more active when listening to simple rhythms than complex rhythms. 
					</p>
					<p class="">
						I am investigating the brain’s preferences for rhythm by presenting chains of participants with rhythmic sequences, where the reproduced sequence of one participant serves as the input sequence for the next participant in the chain, and then analyzing whether the chain converges to a preferred pace or rhythmic structure. Each passage through a link in the chain magnifies the change that one individual introduces. The mathematical model I’ll use to analyze the chains will enable me to make inferences about underlying tempo or rhythmic preferences in the brain based on where the chains seem to converge. Together with pre-existing imaging and behavioral data about rhythm perception, this modeling has the potential to reveal patterns of preferences previously unexplored in earlier experiments.
					</p>

				</div>

				<div class="col-sm-4 citations">
					<p>
						Hannon, E. E., & Trehub, S. E. (2005). Psychological Science, 16(1), 48-55.
					</p>

					<p>
						Grahn, J., & Brett, M. (2007). Cognitive Neuroscience, 19(5), 893-906.
					</p>

					<img style="width:100%" src="images/brain.png" />
					<p class="caption">Image from Grahn, J. A., Henry, M. J., & McAuley, J. D. (2011)</p>

					<p>
						Grahn, J. A., Henry, M. J., & McAuley, J. D. (2011). Neuroimage, 54(2), 1231-1243.
					</p>

					<p>
						Grahn, J. A., & Rowe, J. B. (2009). The Journal of Neuroscience, 29(23), 7540-7548.
					</p>

				</div>
			</section>

			<section class="row">
				<h2 class="col-sm-12" id="detailed-info">detailed background</h2>

				<div class="col-sm-8">
					<p>
						Data from this experiment will help us better understand how the brain processes rhythm. Specifically, it will help to answer the following research questions: 
					</p>
				</div>

				<div class="col-sm-4">
				</div>

				<div class="col-sm-8">
					<p>
						<strong>How do the brain’s hidden preferences for rhythm change what you experience?</strong> <br>
						Perceptual biases are “hidden” preferences that are determined by inherent constraints of the brain. Because a lot of activity in the brain is periodic, it can be synchronized by stimulation from the environment. Take for example, the circadian rhythm, our biological rhythm that lasts about 24 hours. The length of the circadian rhythm in humans is related to the period of oscillating neurons in the suprachiasmatic nucleus (SCN), where daylight in the environment synchronizes the activity in these neurons to the length of a day. However, these neurons have inherent periods that makes some synchronizations difficult. For example, synchronizing to a day on Jupiter, which is equivalent to only 9 hours on Earth, or to Mercury, which is about 1407.5 Earth hours, would be much more difficult. 
					</p>

					<p>
						So, just like the length of a pendulum determines its period of oscillation, physical properties of brain areas such as the SCN determine the periods that these areas can synchronize with. Similarly, neurons in beat-processing areas of the brain may have a range of preferred periods that are able to synchronize better with certain paces, or tempos, in the environment. Hence, pop music or other music we find easier to dance to tends to have a tempo that matches this preferred period.
					</p>

					<p>
						A similar explanation, based on neural oscillatory activity, may apply to preferences for more complex rhythmic patterns. This explanation attributes preferences for rhythmic patterns or meters to resonance between activity in connected brain areas. Resonance refers to communication via neural oscillations between connected brain areas. Similar to the explanation above of tempo preferences, this view says that internal activity in the brain is cyclic. This cyclic activity behaves according to the laws of oscillatory dynamical systems. The pendulum is one example of a dynamical system. The motion of a spring, planetary orbits, or the synchronization of fireflies in the Great Smoky Mountains are additional examples.  Dynamical systems are described by states that evolve over time. For example, a swinging pendulum is passing through many states as it swings. It’s position at the top of a swing or the bottom is called a “state” and can be described mathematically. The passage through various states - from top of swing to bottom, and back again - can also be mathematically described. 
					</p>

					<p>
						Some states are more stable than others. For instance, a pendulum’s stable, equilibrium state is the bottom of its swing: you would never see a pendulum come to a stop at the top of its swing. From this viewpoint, preferred rhythms correspond to stable states of the system. Resonance between oscillators keeping track of various periods of stimulation make some period ratios easier to track (more stable) than others. For instance , a 1:1 ratio of durations is more stable than a 5:7 ratio.
					</p>
				</div>

				<div class="col-sm-4 citations">
					<br>

					<p>Hannon, E. E., Soley, G., & Levine, R. S. (2011). Developmental Science, 14(4), 865-872.
					</p>

					<p>McAuley, J. D., Jones, M. R., Holub, S., Johnston, H. M., & Miller, N. S. (2006). .Journal of Experimental Psychology: General, 135(3), 348.
					</p>

					<p>Hannon, E. E., & Trehub, S. E. (2005). Psychological Science, 16(1), 48-55.
					</p>

					<p>Large, E. W., & Kolen, J. F. (1994). Connection Science, 6(2-3), 177-208.
					</p>

					<p>Treffner, P. J., & Turvey, M. T. (1993). Journal of Experimental Psychology: Human Perception and Performance, 19(6), 1221.
					</p>

					<img style="width:100%; margin-top: 25px" src="images/treffner.png" />
					<p>Image from Treffner & Turvey (1993).</p>

					<p> Mode locking between periods of oscillation can be depicted by Arnold tongues. White regions on this figure show stable period ratios.</p>

					<img style="width:100%" src="images/treffner2.png" />
					<p>Image from Treffner & Turvey (1993).</p>

					<p>Another way of depicting the stable relationships between periods of oscillation is a Farey tree, which is based on a mathematical construction called the Farey sequence. Complexity of a rhythmic ratio increases towards the bottom of the tree.</p>
				</div>

				<div class="col-sm-8">
					<p>
						<strong>How do tempo and meter preferences differ for auditory and visual rhythmic sequences?</strong> <br>

						In day to day life, we perceive auditory and visual events to happen in time with each other. For example, when someone is speaking, the visual signal we receive from moving lips, gestures, or facial expressions usually appears to sync up with their speech or the auditory signal. In fact, it seems very obvious and unsettling when this is untrue; for instance, when the audio and video on a TV are mismatched. Some previous research supports what our day-to-day intuitions suggest: that auditory and visual processing are linked. For example, one previous study demonstrated that auditory brain areas can be recruited to process visual rhythmic patterns. 
					</p>

					<p>
						Yet, previous research has demonstrated that auditory and visual perception are separable. For instance, people have different preferences when they are asked to tap along with visual patterns vs. auditory ones; further, people tend to be worse at discriminating timing perturbations in visual patterns than in auditory patterns. There is an asymmetry in the influence of the two modalities on each other. Other research has demonstrated that auditory rhythms influence our perception of visual patterns, but not vice versa. 
					</p>

					<p>
						The mystery here is why in some cases, visual and auditory processing appear to be distinct, and yet other research (and our everyday experience) suggests otherwise, that audition and vision interact or work in tandem.
					</p>
				</div>

				<div class="col-sm-4 citations">
					<br>
					<br>
					<p>Hove, M. J., Fairhurst, M. T., Kotz, S. A., & Keller, P. E. (2013). Neuroimage, 67, 313-321.</p>

					<p>Grahn, J. A., Henry, M. J., & McAuley, J. D. (2011).  Neuroimage, 54(2), 1231-1243. </p>

					<p>Miller, J. E., Carlson, L. A., & McAuley, J. D. (2012). Psychological Science.</p>

					<p>Repp, B. H. (2003). Journal of Motor Behavior, 35(4), 355-370.</p>

				</div>


				<div class="col-sm-8">
					<p id="methods">
						<strong>Methods</strong> <br>
						Similar to a game of telephone, each participant is presented with a rhythm that was previously reproduced by someone else, just like their reproduction is used as the input for the next participant. Therefore, each person’s reproduction influences the next rhythm that will be heard/seen and reproduced in the chain.
					</p>

					<p>
						This method is called serial reproduction and it has been used by psychologists as early as 1903, one of them being Sir Frederic Charles Bartlett, who used it to study how people’s memory for stories and pictures was shaped by their cultural experiences. 
					</p>

					<p>
						In one study, Bartlett presented his first participant in a chain with an Egyptian hieroglyph and asked him to reproduce it from memory. He then presented that reproduction to the next person in the chain and so on. With each subsequent reproduction, the hieroglyph started to resemble an owl and then became a cat. This was interpreted as a memory bias toward culturally familiar stimuli. In this case, people were more familiar with cats than with Egyptian hieroglyphs. 
					</p>

					<p>
						Likewise, in the case of rhythms, we should expect similar distortions because our brains have certain biases for rhythms we have experienced most often or are hard-wired to prefer.
					</p>

					<img class="center-block" src="images/serial_reproduction.jpg" />
					<p style="text-align:center" class="caption">Image from Xu, J. & Griffiths, T. L. (2010)</p>
				</div>

				<div class="col-sm-4 citations">
					<img src="images/telephone.svg" style="width:100%" />
					<p>
						Bartlett, F. (1932). Cambridge: Cambridge University Press.
					</p>

					<p>
						Xu, J. & Griffiths, T. L. (2010). Cognitive Psychology, 60(2):107--126.
					</p>
				</div>

				<div class="col-sm-8">

					<p id="analysis">
						<strong>Analysis</strong> <br>
						To analyze this data, I will use a mathematical model that will quantify how each reproduction in the chain distorts the information that is passed from person to person. Specifically, this model will characterize each person’s prior experiences and expectations in the form of a prior probability distribution that describes how some things in the world are more likely than other things.
					</p>

					<p>
						In the case of rhythm, the most probable rhythms are the ones we have experienced most often or that our brains are hard-wired to prefer. When we hear and then have to remember a rhythm, our memories are imperfect. We fill in the blanks with the most likely option — that is, we draw from our prior distributions to strengthen our memories. When enough people do this who have similar experiences and expectations, each passage through a reproduction in the chain will nudge the rhythm closer and closer to what we expect, regardless of what the starting point was. 
					</p>

					<p>
						Thus, several reproductions later, the final rhythm will converge on a standard preferred tempo or preferred meter, allowing us to infer the brain’s assignment of probabilities to possible rhythms in the world.
					</p>
				</div>

				<div class="col-sm-4 citations">
					<br>
					<p>
						McAuley, J. D., Jones, M. R., Holub, S., Johnston, H. M., & Miller, N. S. (2006). Journal of Experimental Psychology: General, 135(3), 348.
					</p>

					<p>
						Hannon, E. E., & Trehub, S. E. (2005). Psychological Science, 16(1), 48-55.
					</p>

					<p>
						Parncutt, R. (1994). Music Perception, 409-464.
					</p>

					<p>
						Treffner, P. J., & Turvey, M. T. (1993). Journal of Experimental Psychology: Human Perception and Performance, 19(6), 1221.
					</p>

					<p>
						Xu, J. & Griffiths, T. L. (2010). Cognitive Psychology, 60(2):107--126.
					</p>
				</div>

			</section>

			<section id="about-me" class="row">
				<h2 class="col-sm-12">about the artists</h2>
				<section class="row">
					<div class="col-sm-8">
						<p>
							<a href="http://kimboluti.wordpress.com">Elisa Kim Fromboluti</a> is a graduate student in the <a href="http://taplab.psy.msu.edu/">Timing, Attention, and Perception lab</a> at Michigan State University in East Lansing, MI. Working with Dr. Devin McAuley, she studies how the brain uses and responds to timing and rhythmic cues in the environment, such as those found in speech and music.
						</p>
						<p>
							You can contact her at <a href="mailto:ekfromboluti@gmail.com">ekfromboluti@gmail.com</a>
							<br>
							<div class="social">
								<a href="https://twitter.com/Kimboluti">
									<img src="images/twitter.svg" />
								</a>
								<a href="https://www.facebook.com/TAPlab">
									<img src="images/facebook.svg" />
								</a>
							</div>
						</p>
					</div>

					<div class="col-sm-4 ">
						<img style="width:100%" src="images/ellie.png" />
					</div>
				</section>

				<section class="row">
					<div class="col-sm-8">
						<p>
							<a href="http://www.frombo.com/">Matthew Fromboluti</a> is an architect in Ann Arbor, Michigan. He enjoys building things, especially out of plastic and steel.
						</p>
					</div>

					<div class="col-sm-4">
						<a href="https://www.youtube.com/watch?v=o3Sbq9ukNOk&feature=youtu.be
							">
							<img style="width:100%" src="images/matt.gif" />
						</a>
					</div>
				</section>
			</section>
	</div>

	<footer>
		<embed src="images/bottom.svg" type="image/svg+xml" id="bottom-svg" />
	</footer>
</div>

	<script src="http://d3js.org/d3.v3.min.js"  charset="utf-8"></script>
	<script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/knockout/3.3.0/knockout-min.js'></script>

	<link rel="stylesheet" href="ellie.css">
	<script>
		var data, stimuli;

		var w = 500, h = 500, xPadding = 20, yPadding = 30;

		function checkGrid() {
			var width = window.innerWidth;
			if (width < 768) {
				return "xs";
			}
			if (width >= 768 && width < 992) {
				return "sm";
			}
			if (width >= 992 && width < 1200) {
				return "md";
			}
			if (width >= 1200) {
				return "lg";
			}
		};


		function Viewmodel() {
			var self = this;
			this.currentGrid = undefined;

			this.chainPlaying = ko.observable(false); //is the chain playing?

			this.sessionId = ko.observable(); // session id input
			this.activeSessionId = ko.observable();

			this.chain = ko.observable();
			this.slideInput = ko.observable();

			this.session = ko.computed(function() {
				if (self.activeSessionId() && self.chain()) {
					return self.chain().getSessionById(self.activeSessionId());
				} else {
					return undefined;
				}
			});

			this.chainSessionIndex = ko.computed(function() {
				if (self.slideInput() && self.session()) {
					return self.slideInput() - 1;
				}
			});

			this.chainSessionIndex.subscribe(function(index) {
				self.slideChange(index);
			});

			this.error = ko.observable(undefined);
			this.errorId = ko.observable(undefined);

			this.canvas = undefined;

			this.hideErrorBars = ko.observable(false);
			this.hideSource = ko.observable(false);

			this.transitionSpeed = 800;

			this.initSvg = function() {
				this.canvas = d3.select("div#canvas-container")
		        	.append("svg")
		        	.attr("id", "dv")
		        	.attr("width", w)
		        	.attr("height", h);

		        var xScale = d3.scale.linear()
					.domain([0, 1000])
					.range([0, w]);

				var xAxis = d3.svg.axis()
					.scale(xScale)
					.orient("top")
					.ticks(4);

				this.canvas.append("g")
			        	.attr("class", "axis")
			        	.attr("id", "x-axis")
			        	.attr("transform", "translate(0, 45)")
			        	.call(xAxis);

			    this.canvas.append("text")
			    	.attr("id", "axis-label")
			    	.attr("class", "axis-label")
			    	.attr("text-anchor", "middle")
			    	.attr("x", w / 2)
			    	.attr("y", yPadding / 2)
			    	.text("Time Between Taps (ms)");		    
	
			    this.fetchSession(1306);
			};

			this.refreshSvg = function() {
				var width = document.getElementById("dv-container").offsetWidth;
				var currentG = checkGrid();

				if (this.currentGrid != currentG) {
					this.currentGrid = currentG;
					if (currentG == 'md' || currentG == 'lg') {
						xPadding = 20;
						w = width;
						h = 500;
					}
					if (currentG == 'sm') {
						xPadding = 20;
						w = width;
						h = 400;
					}
					if (currentG == 'xs') {
						xPadding = 15;
						w = width - xPadding * 2;
						h = 350;
					}


					d3.select('#dv')
						.attr("width", w )
						.attr("height", h);

					var xScale = d3.scale.linear()
						.domain([0, 1000])
						.range([0, w]);

					var xAxis = d3.svg.axis()
						.orient("top")
						.scale(xScale)
						.ticks(4);

					this.canvas.select("#x-axis")
						.attr("class", "axis")
						.attr("id", "x-axis")
						.attr("transform", "translate(0, 45)")
						.call(xAxis);

					this.canvas.select("#axis-label")
						.attr("class", "axis-label")
						.attr("text-anchor", "middle")
						.attr("x", w/2)
						.attr("Y", yPadding/2);

					this.plotSession();
				}
			};

			this.fetchSession = function(inputId) {
				var id = typeof inputId === 'number' ? inputId : this.sessionId();

				if (data[id]) {
					this.sessionId('');
					this.error("");
					this.errorId("");

					this.slideInput(''); // clear previous slideInput
					this.activeSessionId(id);
					this.initChain(data[id].ChainID);

					this.plotSession();

				} else {
					if (!this.sessionId()) {
						this.errorId("");
						this.error("Please type in a valid Participant ID");
					} else {
						this.errorId(id);
						this.error(" doesn't exist. Please double check that you have entered the correct ID.");
					}
				}

			};

			this.initChain = function(chainId) {
				var chain = new Chain(this.getChain(chainId));
				chain.sortSessions();
				this.chain(chain);

				if ( !this.chain().getSessionById(this.activeSessionId()) ) {
					// if the chain doesn't retrieve the session it means that it was rejected
					// just show the first generation of the chain and display error message

					this.errorId(this.activeSessionId());
					this.error(" You're an outlier. We couldn't use you in this chain, but here is the data for the chain you would have been in.");

					var id = this.chain().getSessionByIndex(0).ID;
					this.activeSessionId(id);
					this.slideInput(1);
				} else {
					var index = this.chain().getSessionIndexById(this.activeSessionId());
					this.slideInput(index + 1);
				}
				
			};

			this.getChain = function(chainId) {
				var chain = [];
				for (var key in data) {
					if (data[key].ChainID == chainId) {
						var element = data[key];
						element.ID = key;
						chain.push(new Session(element));
					}
				};

				return chain;
			};

			this.getDataElementById = function(id) {
				if (id >= 1000) {
					var element = data[id];

					if (element) { 
						element.ID = id;
						return element; 
					} 
					else { return false; }
				} else {
					// fetch seed stimuli

					this.getStimuli()
				}
				
			};

			this.getStimuli = function(seed, type) {
				var key = seed + type;

				var values = {
					"0t": stimuli["1"],
					"1t": stimuli["2"],
					"2t": stimuli["3"],
					"3t": stimuli["4"],
					"0m": stimuli["5"],
					"1m": stimuli["6"],
					"2m": stimuli["7"],
					"3m": stimuli["8"]
				};

				return values[key];
			};

			this.slideChange = function(index) {
				if (index != undefined) {
					var session = this.chain().getSessionByIndex(this.chainSessionIndex());
					this.activeSessionId(session.ID);
					this.plotSession();
				}	
			};

			this.plotSession = function() {
				var session = this.session();
				var sessionStimuli = this.getStimuli(session.Seed, session.Type);

				if (session.SourceID >= 1000) {
					var sessionSource = new Session( this.getDataElementById(session.SourceID) );
				} else {
					var sessionSource = {Tapping: sessionStimuli.SeedStimuli};
				}

				var domainMin = 0; //= d3.min(sessionStimuli.SeedStimuli, function(d) { return d; }) - 750;
				var domainMax = 500 + d3.max(sessionStimuli.SeedStimuli, function(d) {return d;});

				var xScale = d3.scale.linear()
		        	.domain([domainMin, domainMax])
		        	.range([xPadding, w - xPadding]);

		        var yScale = d3.scale.linear()
		    		.domain([0, sessionStimuli.SeedStimuli.length])
		    		.range([yPadding * 2, h]);

		        var bothData = [];

		        for ( var i = 0; i < sessionSource.Tapping.length; i++ ) {
		        	bothData.push( {source: sessionSource.Tapping[i], 
		        					session: session.Tapping[i] } );
		        };


		        var errorMargins = this.canvas.selectAll(".error-margin")
		        	.data(bothData);

		        errorMargins
		        	.transition()
		        	.duration(self.transitionSpeed)
		        		.attr("class", function(d) {
		        			if (d.session && d.source) {			
			        			if (self.hideErrorBars()) {
			        				if (d.session > d.source) {
			        					return "error-margin";
				        			} else {
				        				return "error-margin";
				        			}
			        			} else {
			        				if (d.session > d.source) {
				        				return "error-margin slower";
				        			} else {
				        				return "error-margin faster";
				        			}
			        			}
			        		};
		        		})
		        		.attr("x1", function(d) {
		        			if (d.session) {
			        			return xScale(d.session);		        				
		        			}
		        		})
		        		.attr("y1", function(d, i) {
		        			return yScale(i);
		        		})
		        		.attr("x2", function(d) {
		        			return xScale(d.source);
		        		})
		        		.attr("y2", function(d, i) {
		        			return yScale(i);
		        		});
		        errorMargins
		        	.enter()
		        		.append("line")
		        		.attr("class", function(d) {
		        			if (d.session && d.source) {
			        			if (self.hideErrorBars()) {
			        				if (d.session > d.source) {
				        				return "error-margin";
				        			} else {
				        				return "error-margin";
				        			}
			        			} else {		        			
				        			if (d.session > d.source) {
				        				return "error-margin slower";
				        			} else {
				        				return "error-margin faster";
				        			}
				        		}
				        	}
		        		})
		        		.attr("x1", function(d) {
		        			if (d.session) {
			        			return xScale(d.session);
		        			}
		        		})
		        		.attr("y1", function(d, i) {
		        			return yScale(i);
		        		})
		        		.attr("x2", function(d) {
		        			return xScale(d.source);
		        		})
		        		.attr("y2", function(d, i) {
		        			return yScale(i);
		        		});

		        errorMargins
		        	.exit()
		        		.remove(); 

		       	var sourcePoints = this.canvas.selectAll(".source-point")
		        	.data(bothData);

		        sourcePoints
		        	.transition()
		        	.duration(self.transitionSpeed)
		        		.attr("r", function(d) {
		        			if (d.session && d.source) {
		        				return 7;		
		        			}
		        		})
		       			.attr("cx", function(d) {
		       				if (d.source && d.session) {
		       					return xScale(d.source);
		       				}
		        		})
		        		.attr("cy", function(d, i) {
		        			if (d.source && d.session) {		        			
		        				return yScale(i);
		        			}
		        		})
		        		.attr("class", function(d) {
		        			if (d.session && d.source) {
			        			if (self.hideSource()) {
			        				if (d.session > d.source ) {
				        				return "source-point";
				        			} else {
				        				return "source-point";
				        			}
			        			} else {
			        				if (d.session > d.source ) {
				        				return "source-point slower";
				        			} else {
				        				return "source-point faster";
				        			}
			        			}
			        		}
		        		});

		        sourcePoints
		        	.enter()
		        		.append("circle")
		        		.attr("r", function(d) {
		        			if (d.session && d.source) {
		        				return 7;		
		        			}
		        		})
		        		.attr("cx", function(d) {
		        			if (d.session && d.source) {
		        				return xScale(d.source);
		        			}
		        		})
		        		.attr("cy", function(d, i) {
		        			if (d.session && d.source) {
		        				return yScale(i);
		        			}
		        		})
		        		.attr("class", function(d, i) {
		        			if (d.session && d.source) {
		        				if (self.hideSource()) {
				        			if (d.session > d.source ) {
				        				return "source-point";
				        			} else {
				        				return "source-point";
				        			}
				        		} else {
				        			if (d.session > d.source) {
				        				return "source-point slower";
				        			} else {
				        				return "source-point faster";
				        			}
				        		}
			        		}
		        		});

		        sourcePoints
		        	.exit()
		        		.remove();

		        
		        var seedLine = this.canvas.selectAll("line.seed-line")
		        	.data(sessionStimuli.SeedStimuli);

		        seedLine
		        	.transition()
		        	.duration(self.transitionSpeed * 1.5)
			        	.attr("x1", function(d) {
			        		return xScale(d);
			        	})
			        	.attr("y1", function(d, i) {
			        		return (yScale(i) - 6);
			        	})
			        	.attr("x2", function(d) {
			        		return xScale(d);
			        	})
			        	.attr("y2", function(d, i) {
			        		return (yScale(i) + 6);
			        	});

			    seedLine
		        	.enter()
			        	.append("line")
			        	.attr("x1", function(d) {
			        		return xScale(d);
			        	})
			        	.attr("y1", function(d, i) {
			        		return (yScale(i) - 6);
			        	})
			        	.attr("x2", function(d) {
			        		return xScale(d);
			        	})
			        	.attr("y2", function(d, i) {
			        		return (yScale(i) + 6);
			        	})
			        	.attr("class", "seed-line");

			    seedLine
		        	.exit()
		        		.remove();

			    var seedLabel = this.canvas.select(".seed-label")
			    	.data(sessionStimuli.SeedStimuli);

			    seedLabel
			    		.attr("transform", function(d) {
			    			return "rotate(-90 " + (xScale(d) + 12) + "," + (h - yPadding * 1.2) + ")";
			    		})
			    		.attr("y", h - yPadding * 1.2 )
			    	.transition()
			    	.duration(self.transitionSpeed * 1.5)
			   			.attr("x", function(d) {
			   				return xScale(d) + 12;
			   			})
			   			.attr("text-anchor", "beginning")
			    		.text("Original Source");
			    seedLabel
			   		.enter()
			   			this.canvas.append("text")
			   			.attr("class", "seed-label"); 

			    seedLabel
			    	.exit()
			    		.remove();
				
				var dataPoints = this.canvas.selectAll(".data-point")
					.data(session.Tapping);

				dataPoints
					.transition()
					.duration(self.transitionSpeed)
			        	.attr("cx", function(d) {
			        		return xScale(d);
			       		})
			        	.attr("cy", function(d, i) {
			        		return yScale(i);
			        	})
			        	.attr("class", "data-point");

			    dataPoints
					.enter()
		        		.append("circle")
		        		.attr("r", function(d) {
		        			return 7;
		        		})
		        		.attr("cx", function(d) {
			        		return xScale(d);
			       		})
			        	.attr("cy", function(d, i) {
			        		return yScale(i);
			        	})
			        	.attr("class", "data-point");

		        dataPoints
		        	.exit()
		        		.remove();

		        var xAxis = d3.svg.axis()
					.scale(xScale)
					.orient("top")
					.ticks(5);
					
		        this.canvas.select("#x-axis")
		        	.call(xAxis);

		        
		        var activeGeneration = this.canvas.selectAll(".activeGeneration")
		        	.data([0]);

		        activeGeneration
		        		.attr("x", w - xPadding )
			    		.attr("y", h - yPadding)
			    		.text(self.slideInput())
		    		.enter()
		    			.append("text")
		    			.attr("text-anchor", "end")
			    		.attr("class", "activeGeneration");
			    		

			};

			this.chainToggle = function() {
				// chain is not playing
				if (!self.chainPlaying()) {
					self.chainPlaying(true);
					self.hideErrorBars(true);
					self.hideSource(true);

					self.slideInput(1);
					chainPlay = setInterval(function() {
						if (self.slideInput() < self.chain().sessions.length) {
							self.slideInput(Number(self.slideInput()) + 1);
						} else {
							clearInterval(chainPlay);
							self.chainPlaying(false);

							self.hideErrorBars(false);
							self.hideSource(false);
							self.plotSession();
						}
					}, 900);
				} else { //chain is playing so cancel it
					self.chainPlaying(false);
					clearInterval(chainPlay);

					self.hideErrorBars(false);
					self.hideSource(false);

					self.plotSession();
				}
				
			};
		};
		

		function Session(params) {
			for (key in params) {
				this[key] = params[key];
			}
		}

		Session.prototype.getAverage = function() {
			var sum = 0;

			for (var i = 0; i < this.taps.length; i++) {
				sum += Number(this.taps[i]);
			}

			return sum / this.taps.length;
		}

		function Chain(array) {
			this.sessions = array;
			this.rejects = [];
		}

		Chain.prototype.getSessionById = function(id) {
			var session;

			this.sessions.map(function(element) {
				if (Number(element.ID) == Number(id)) {
					session = element;
				}
			});

			return session;
		}

		Chain.prototype.getSessionIndexById = function(id) {
			var index;

			this.sessions.map(function(element, i) {
				if (Number(element.ID) == Number(id)) {
					index = i;
				}
			});

			return index;
		}

		Chain.prototype.getSessionByIndex = function(index) {
			var session = this.sessions[index];
			return session;
		}

		Chain.prototype.sortSessions = function() {
			var reject = [];
			var keep = [];

			this.sessions.map(function(element, index) {
				if (element.Chain[0] === 'r') {
					reject.push(element);
				} else {
					keep.push(element);
				}
			}, this);

			this.sessions = keep;
			this.rejects = reject;

			function compare(a,b) {
				if (Number(a.Chain) < Number(b.Chain)) {
					return -1;
				}
				if (Number(a.Chain) > Number(b.Chain)) {
					return 1;
				}
				return 0
			}

			this.sessions.sort(compare);
		}

		Chain.prototype.getTappingMaxValue = function() {
			var sessions = this.sessions;
			var values = [];

			for (var i = 0; i < sessions.length; i++ ) {
				sessions[i]['Tapping'].map(function(element) {
					values.push(Number(element));
				});
			}

			var max = Math.max.apply(Math, values);
			return max;
		}

		Chain.prototype.getTappingMinValue = function() {
			var sessions = this.sessions;
			var values = [];

			for (var i = 0; i < sessions.length; i++ ) {
				sessions[i]['Tapping'].map(function(element) {
					values.push(Number(element));
				});
			}

			var min = Math.min.apply(Math, values);
			return min;
		}

	    
		d3.json('updated.json', function(json) {
			data = json;

			d3.json('stimuli.json', function(json) {
				stimuli = json;

				var vm = new Viewmodel();
				ko.applyBindings(vm);
				vm.initSvg();
				vm.refreshSvg();

				var isMobile = { 
					Android: function() { return navigator.userAgent.match(/Android/i); }, 
					BlackBerry: function() { return navigator.userAgent.match(/BlackBerry/i); }, 
					iOS: function() { return navigator.userAgent.match(/iPhone|iPad|iPod/i); }, 
					Opera: function() { return navigator.userAgent.match(/Opera Mini/i); }, 
					Windows: function() { return navigator.userAgent.match(/IEMobile/i); }, 
					any: function() { return (isMobile.Android() || isMobile.BlackBerry() || isMobile.iOS() || isMobile.Opera() || isMobile.Windows()); } 
				};

				if (!isMobile.any()) {
					window.addEventListener("resize", function(){
					    vm.refreshSvg();
					});
				}
				
			});
		});
	</script>
</body>
</html>